name: Alert Response Pipeline

on:
  repository_dispatch:
    types: [alert-triggered]
  workflow_dispatch:
    inputs:
      alert_type:
        description: 'Type of alert'
        required: true
        default: 'HighErrorRate'
      severity:
        description: 'Alert severity'
        required: true
        default: 'critical'

permissions:
  contents: write
  packages: write
  issues: read
  checks: read
  statuses: read

jobs:
  alert-response:
    name: üö® Alert Response
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Parse Alert Payload
        id: alert
        run: |
          if [ "${{ github.event_name }}" = "repository_dispatch" ]; then
            ALERT_TYPE="${{ github.event.client_payload.alert_type }}"
            SEVERITY="${{ github.event.client_payload.severity }}"
            DESCRIPTION="${{ github.event.client_payload.description }}"
            VALUE="${{ github.event.client_payload.value }}"
          else
            ALERT_TYPE="${{ github.event.inputs.alert_type }}"
            SEVERITY="${{ github.event.inputs.severity }}"
            DESCRIPTION="Manual trigger for $ALERT_TYPE"
            VALUE="manual"
          fi

          echo "alert_type=$ALERT_TYPE" >> $GITHUB_OUTPUT
          echo "severity=$SEVERITY" >> $GITHUB_OUTPUT
          echo "description=$DESCRIPTION" >> $GITHUB_OUTPUT
          echo "value=$VALUE" >> $GITHUB_OUTPUT

      - name: Setup kubectl
        if: steps.alert.outputs.alert_type == 'ServiceDown' || steps.alert.outputs.alert_type == 'HighErrorRate'
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.28.0'

      - name: Emergency Rollback Deployment
        if: steps.alert.outputs.alert_type == 'HighErrorRate' && steps.alert.outputs.severity == 'critical'
        run: |
          echo "üö® CRITICAL: High error rate detected - initiating emergency rollback"

          # Get current deployment info
          CURRENT_IMAGE=$(kubectl get deployment balance-sheet-pro -o jsonpath='{.spec.template.spec.containers[0].image}')
          echo "Current image: $CURRENT_IMAGE"

          # Find previous image tag (assuming semantic versioning)
          # This is a simplified example - in production you'd have better version tracking
          if kubectl get deployment balance-sheet-pro-prev 2>/dev/null; then
            PREV_IMAGE=$(kubectl get deployment balance-sheet-pro-prev -o jsonpath='{.spec.template.spec.containers[0].image}')
            echo "Rolling back to: $PREV_IMAGE"

            # Update deployment with previous image
            kubectl set image deployment/balance-sheet-pro api=$PREV_IMAGE
            kubectl rollout status deployment/balance-sheet-pro --timeout=300s

            echo "‚úÖ Rollback completed successfully"
          else
            echo "‚ö†Ô∏è No previous deployment found - manual intervention required"
          fi

      - name: Service Recovery Actions
        if: steps.alert.outputs.alert_type == 'ServiceDown'
        run: |
          echo "üö® Service down detected - attempting recovery"

          # Check pod status
          kubectl get pods -l app=balance-sheet-pro

          # Try to restart pods
          kubectl rollout restart deployment balance-sheet-pro
          kubectl rollout status deployment/balance-sheet-pro --timeout=300s

          # Verify service is back up
          if kubectl get svc balance-sheet-pro &>/dev/null; then
            echo "‚úÖ Service recovery completed"
          else
            echo "‚ùå Service recovery failed - manual intervention required"
          fi

      - name: Scale Up Response
        if: steps.alert.outputs.alert_type == 'HighLatency' && steps.alert.outputs.severity == 'warning'
        run: |
          echo "‚ö†Ô∏è High latency detected - scaling up application"

          # Temporarily increase replica count
          kubectl scale deployment balance-sheet-pro --replicas=5
          kubectl rollout status deployment/balance-sheet-pro --timeout=300s

          echo "‚úÖ Scaled up to 5 replicas"

      - name: Database Issue Response
        if: steps.alert.outputs.alert_type == 'DatabaseConnectionIssues'
        run: |
          echo "‚ö†Ô∏è Database connection issues detected"

          # Check database pod status
          kubectl get pods -l app=balance-sheet-pro

          # Restart application pods to refresh connections
          kubectl rollout restart deployment balance-sheet-pro
          kubectl rollout status deployment/balance-sheet-pro --timeout=300s

          echo "‚úÖ Application pods restarted to refresh database connections"

      - name: Notify Response Action
        if: always()
        run: |
          ALERT_TYPE="${{ steps.alert.outputs.alert_type }}"
          SEVERITY="${{ steps.alert.outputs.severity }}"
          ACTION_TAKEN="${{ job.status }}"

          MESSAGE="üö® Alert Response: $ALERT_TYPE ($SEVERITY)"
          if [ "$ACTION_TAKEN" = "success" ]; then
            MESSAGE="$MESSAGE\\n‚úÖ Automated response completed successfully"
          else
            MESSAGE="$MESSAGE\\n‚ùå Automated response failed - manual intervention required"
          fi

          curl -X POST -H 'Content-type: application/json' \
          --data "{\"text\":\"$MESSAGE\\n<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Response Details>\"}" \
          ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Create Incident Issue
        if: steps.alert.outputs.severity == 'critical' && steps.alert.outputs.alert_type == 'ServiceDown'
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® Critical Incident: Service Down - ${new Date().toISOString()}`,
              body: `
            ## Critical Incident Alert
            
            **Alert Type:** Service Down
            **Severity:** Critical
            **Time:** ${new Date().toISOString()}
            **Description:** Application service is unavailable
            
            ## Automated Actions Taken
            - Attempted pod restart
            - Rollout status check
            
            ## Next Steps
            - [ ] Investigate root cause
            - [ ] Check application logs
            - [ ] Verify database connectivity
            - [ ] Test service recovery
            - [ ] Update stakeholders
            
            ## Related Links
            - [Application Logs](http://localhost:5601)
            - [Metrics Dashboard](http://localhost:3001)
            - [CI/CD Pipeline](${{ github.server_url }}/${{ github.repository }}/actions)
            `,
              labels: ['incident', 'critical', 'automated-response']
            })

      - name: Performance Investigation
        if: steps.alert.outputs.alert_type == 'HighLatency' || steps.alert.outputs.alert_type == 'HighCPUUsage'
        run: |
          echo "üìä Performance investigation triggered"

          # Collect diagnostic information
          echo "## Performance Diagnostics" >> $GITHUB_STEP_SUMMARY
          echo "- Alert Type: ${{ steps.alert.outputs.alert_type }}" >> $GITHUB_STEP_SUMMARY
          echo "- Severity: ${{ steps.alert.outputs.severity }}" >> $GITHUB_STEP_SUMMARY
          echo "- Value: ${{ steps.alert.outputs.value }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Add investigation checklist
          echo "## Investigation Checklist" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Check application logs for errors" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Review recent deployments" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Analyze resource usage trends" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Check database performance" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Review recent code changes" >> $GITHUB_STEP_SUMMARY